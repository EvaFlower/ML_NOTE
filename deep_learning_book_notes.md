
## Chapter 5 Machine Learning Basics  
5.1 various tasks in machine learning; 0-1 loss on classification to measure accuracy of the model; average log-probability  
 of the model assigning to the samples on density estimation; mean square loss n the linear regression
 
5.2 Capacity of model; underfitting and overfitting; Occam's razor -- simple working model is better; VC dimension; no free   
lunch theorem; regularization
  
5.3 training data -- training set (80%) and validation set (20%); testing data -- test set; k-fold cross-validation for small  
dataset
  
5.4 bias of an estimator: unbiased estimator; variance of an estimator: biased estimate of the trun standard deviation of  
data, use square root of the unbiased estimator of the variance, can calculate the like 95% confidence interval centered on  
the estimator, compare A and B algorithm  

